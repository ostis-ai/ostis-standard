\begin{SCn}
	
\scnsectionheader{\currentname}
	
\scnstartsubstruct
	
\scnheader{Предметная область искусственных нейронных сетей}
\scniselement{предметная область}
\scnsdmainclasssingle{искусственная нейронная сеть}

\scnrelfromset{частная предметная область}{
Предметная область ИНС с заданным направлением связей\\
    \scnaddlevel{1}
    \scnrelfromset{частная предметная область}{
    Предметная область ИНС с прямым связями\\
        \scnaddlevel{1}
        \scnrelfromset{частная предметная область}{
        Предметная область персептронов\\
            \scnaddlevel{1}
            \scnrelfromset{частная предметная область}{
            Предметная область персептронов Розенблатта
            ;Предметная область персептронов Румельхарта
            ;Предметная область автоэнкодерных ИНС
            }
            \scnaddlevel{-1}
        ;Предметная область ИНС радиально-базисных функций
        ;Предметная область машин опорных векторов
        }
        \scnaddlevel{-1}
    ;Предметная область ИНС с обратными связями\\
        \scnaddlevel{1}
        \scnidtf{Предметная область рекуррентных ИНС}
        \scnrelfromset{частная предметная область}{
        Предметная область ИНС Джордана
        ;Предметная область ИНС Элмана
        ;Предметная область LSTM-элементов
        ;Предметная область GRU-элементов
        }
        \scnaddlevel{-1}
    }
    \scnaddlevel{-1}
;Предметная область обучения ИНС\\
    \scnaddlevel{1}
    \scnrelfromset{частная предметная область}{
    Предметная область ИНС, обучающихся с учителем
    ;Предметная область ИНС, обучающихся без учителя\\
        \scnaddlevel{1}
        \scnrelfromset{частная предметная область}{
        Предметная область обучающихся автоэнкодерных ИНС
        ;Предметная область ИНС глубокого доверия
        ;Предметная область генеративно-состязательных ИНС
        ;Предметная область самоорганизующихся карт Кохонена
        ;Предметная область ИНС Хопфилда
        ;Предметная область подкрепляющего обучения ИНС
        }
        \scnaddlevel{-1}
    }
    \scnaddlevel{-1}
;Предметная область топологий ИНC\\
    \scnaddlevel{1}
    \scnrelfromset{частная предметная область}{
    Предметная область полносвязных ИНC
    ;Предметная область многослойных ИНC
    ;Предметная область слабосвязных ИНC
    }
    \scnaddlevel{-1}
;Предметная область задач, решаемых с помощью ИНС\\
    \scnaddlevel{1}
    \scnrelfromset{частная предметная область}{
    Предметная область ИНС, решающих задачу классификации
    ;Предметная область ИНС, решающих задачу аппроксимации
    ;Предметная область ИНС, решающих задачу управления
    ;Предметная область ИНС, решающих задачу фильтрации
    ;Предметная область ИНС, решающих задачу детекции
    ;Предметная область ИНС, решающих задачу с ассоциативной памятью
    }
    \scnaddlevel{-1}
;Предметная область интеграции ИНС с базой знаний
}
\scnheader{искусственная нейронная сеть}
\scnaddlevel{1}
	\scnidtf{и.н.с.}
	\scnidtf{нейронная сеть}
	\scnidtf{биологически инспирированная математическая модель, обладающая обобщающей способностью после выполнения процедуры обучения}
	\scniselement{математическая модель}
\scnaddlevel{-1}

\scnheader{математическая модель}
\scnaddlevel{1}
	\scnidtf{упрощенное описание объекта реального мира, выраженное с помощью математической символики}
\scnaddlevel{-1}

\scnheader{обобщающая способность}
\scnaddlevel{1}
	\scnidtf{generalization ability}
	\scnidtf{способность модели выдавать корректные результаты для экземпляров, не входящих в обучающую выборку}
\scnaddlevel{-1}

\scnheader{экземпляр}
\scnaddlevel{1}
	\scnidtf{instance}
	\scnidtf{пример}
	\scnidtf{example}
	\scnidtf{образ}
	\scnidtf{один объект, наблюдение, транзакция или запись, выраженный в виде вектора или матрицы, компоненты которого представлены численными и/или категориальными значениями}
\scnaddlevel{-1}

\scnheader{признаки}
\scnaddlevel{1}
	\scnidtf{features}
	\scnidtf{входные атрибуты, используемые для предсказания целевой переменной}
	\scnidtf{компоненты вектора или матрицы экземпляра}
	\scnnote{могут быть как численными, так и категориальными}
\scnaddlevel{-1}

\scnheader{обучающая выборка}
\scnaddlevel{1}
	\scnidtf{выборка экземпляров, используемая для изменения параметров н.с. в процессе ее обучения}
	\scnidtf{training set}
\scnaddlevel{-1}

\scnheader{параметры нейронной сети}
\scnaddlevel{1}
\scnidtf{переменные, значения которых изменяются в ходе процедуры обучения}
\scnidtf{компоненты векторов весовых коэффициентов, ядер свертки и пороги нейронов и.н.с.}
\scnaddlevel{-1}

\scnheader{вектор весовых коэффициентов}
\scnaddlevel{1}
	\scnidtf{вектор параметров отдельно взятого нейрона, компоненты которого изменяются в процессе обучения и.н.с.}
\scnaddlevel{-1}

\scnheader{ядро свертки}
\scnaddlevel{1}
	\scnidtf{квадратная матрица произвольной размерности, компоненты которой изменяются в процессе обучения и.н.с.}
\scnaddlevel{-1}

\scnheader{порог нейрона}
\scnaddlevel{1}
	\scnidtf{скаляр, значение которого изменяется в процессе обучения и.н.с.}
\scnaddlevel{-1}

\scnheader{нейрон}
\scnaddlevel{1}
	\scnidtf{отдельный обрабатывающий элемент и.н.с., выполняющий функциональное преобразование взвешенной суммы компонент вектора входных значений с помощью функции активации}
	\scnidtf{отдельный обрабатывающий элемент и.н.с., выполняющий функциональное преобразование результата операции свертки матрицы входных значений с помощью функции активации}
	\scnidtf{математическая модель реального биологического нейрона}
	\scnrelfromvector{виды нейронов и.н.с.}{
		полносвязный нейрон\\
		\scnaddlevel{1}
			\scnidtf{нейрон, у которого есть полный набор связей с нейронами предшествующего слоя}
		\scnaddlevel{-1}
		;сверточный нейрон
		;рекуррентный нейрон
	}
	\scniselement{и.н.с.}
\scnaddlevel{-1}

\scnheader{связь}
\scnaddlevel{1}
	\scnidtf{логическое соединение между двумя нейронами, характеризующееся соответствующим компонентом вектора весовых коэффициентов или ядра свертки}
\scnaddlevel{-1}

\scnheader{вектор входных значений}
\scnaddlevel{1}
	\scnidtf{вектор экземпляра, компоненты которого прошли предварительную обработку}
	\scnexplanation{такая предварительная обработка как правило включает в себя трансформацию категориальных признаков в численные, а также нормализацию, проектирование признаков, обработку нейронами предшествующих слоев и.н.с. и т.д.}
\scnaddlevel{-1}

\scnheader{матрица входных значений}
\scnaddlevel{1}
	\scnidtf{матрица экземпляра, компоненты которого прошли предварительную обработку}
	\scnexplanation{такая предварительная обработка как правило включает в себя трансформацию категориальных признаков в численные, а также нормализацию, проектирование признаков, обработку нейронами предшествующих слоев и.н.с. и т.д.}
\scnaddlevel{-1}

\scnheader{взвешенная сумма входных значений}
\scnaddlevel{1}
	\scnidtf{сумма покомпонентного произведения векторов входных значений и весовых коэффициентов нейрона}
	\scnidtf{взвешенная сумма}
	\scnidtf{в.с.}
	\scnrelfrom{формула}{
		\begin{equation*}
			S = \sum_{i=1}^{n} w_ix_i
		\end{equation*}
		где \textit{n} -- размерность вектора входных значений, $w_i$ -- \textit{i}-тый компонент вектора весовых коэффициентов, $x_i$ -- \textit{i}-тый компонент вектора входных значений
	}
\scnaddlevel{-1}

\scnheader{функция активации нейрона}
\scnaddlevel{1}
	\scnidtf{функция, результат применения которой к в.с. нейрона определяет его выходное значение}
	\scnrelfromvector{виды функций активации}{
		линейная\\
		\scnaddlevel{1}
		\scnrelfrom{формула}{
			\begin{equation*}
				y = kS
			\end{equation*}
			где \textit{k} -- коэффициент наклона прямой, \textit{S} -- в.с.
		}
		\scnaddlevel{-1}
		;пороговая\\
		\scnaddlevel{1}
		\scnrelfrom{формула}{
			\begin{equation*}
				y = sign(S) = 				
				\begin{cases}
					1, S > 0,\\
					0, S \leq 0
				\end{cases}
			\end{equation*}
		}
		\scnaddlevel{-1}
		;сигмоидная\\
		\scnaddlevel{1}
		\scnrelfrom{формула}{
			\begin{equation*}
				y = \frac{1}{1+e^{-cS}}
			\end{equation*}
			где \textit{с} > 0 -- коэффициент, характеризующий ширину сигмоидной функции по оси абсцисс, \textit{S} -- в.с.
		}
		\scnaddlevel{-1}
		;гиперболический тангенс\\
		\scnaddlevel{1}
		\scnrelfrom{формула}{
			\begin{equation*}
				y = \frac{e^{cS}-e^{-cS}}{e^{cs}+e^{-cS}}
			\end{equation*}
			где \textit{с} > 0 -- коэффициент, характеризующий ширину сигмоидной функции по оси абсцисс, \textit{S} -- в.с.
		}
		\scnaddlevel{-1}
		;softmax\\
		\scnaddlevel{1}
		\scnrelfrom{формула}{
			\begin{equation*}
				y_j = softmax(S_j) = \frac{e^{S_j}}{\sum_{j} e^{S_j}}
			\end{equation*}
			где $S_j$ -- в.с. \textit{j}-го выходного нейрона
		}
		\scnaddlevel{-1}
		;ReLU\\
		\scnaddlevel{1}
		\scnrelfrom{формула}{
			\begin{equation*}
				y = F(S) =
				\begin{cases}
					S, S > 0,\\
					kS, S \leq 0
				\end{cases}
			\end{equation*}
			где \textit{k} = 0 или принимает небольшое значение, например, 0.01 или 0.001.
		}
		\scnaddlevel{-1}
	}
\scnaddlevel{-1}

\scnheader{тестовая выборка}
\scnaddlevel{1}
	\scnidtf{test set}
	\scnidtf{контрольная выборка}
	\scnidtf{выборка экземпляров, используемая для проверки обобщающей способности обученной и.н.с.}
	\scnnote{элементы контрольной выборки не используются в процессе обучения}
\scnaddlevel{-1}

\scnheader{валидационная выборка}
\scnaddlevel{1}
	\scnidtf{выборка экземпляров, используемая для определения (настройки) гиперпараметров (архитектуры) и.н.с.}
	\scnnote{элементы валидационной выборки не используются в процессе обучения}
\scnaddlevel{-1}

\scnheader{гиперпараметры и.н.с}
\scnaddlevel{1}
\scnidtf{набор параметров и.н.с., определяющих ее архитектуру (количество слоев и.н.с., количество нейронов в каждом слое и т.д.)}
\scnaddlevel{-1} 

\scnheader{слой и.н.с.}
\scnaddlevel{1}
	\scnidtf{вектор нейронов и.н.с., осуществляющих параллельную независимую обработку вектора или матрицы входных значений}
	\scniselement{и.н.с.}
	\scnrelfromvector{виды слоев и.н.с.}{
		полносвязный слой\\
		\scnaddlevel{1}
			\scnidtf{слой, в котором каждый нейрон имеет связь с каждый нейроном предшествующего слоя}
			\scnidtf{слой, в котором каждый нейрон является полносвязным}
		\scnaddlevel{-1}
		;сверточный слой\\
		\scnaddlevel{1}
			\scnidtf{слой, в котором каждый нейрон является сверточным}
		\scnaddlevel{-1}
		;слой нелинейного преобразования\\
		\scnaddlevel{1}
			\scnidtf{слой, осуществляющий нелинейное преобразование входных данных}
			\scnexplanation{как правило, выделяются в отдельные слои только в программных реализациях. Фактически рассматриваются как финальный этап расчета выходной активности любого нейрона -- применение функции активации}
			\scnnote{не изменяет размерность входных данных}
		\scnaddlevel{-1}
		;dropout слой\\
		\scnaddlevel{1}
			\scnidtf{слой, реализующий технику регуляризации dropout}
			\scnnote{данный тип слоя функционирует только во время обучения и.н.с.}
		\scnaddlevel{-1}
		;pooling слой\\
		\scnaddlevel{1}
			\scnidtf{подвыборочный слой}
			\scnidtf{объединяющий слой}
			\scnidtf{слой, осуществляющий уменьшение размерности входных данных}
		\scnaddlevel{-1}
		;слой локальной нормализации\\
		\scnaddlevel{1}
		\scnaddlevel{-1}
		;слой батч-нормализации\\
		\scnaddlevel{1}
		\scnaddlevel{-1}	
	}
\scnaddlevel{-1}

\scnheader{обучение}
\scnaddlevel{1}
	\scnidtf{процесс итеративного изменения параметров и.н.с., минимизирующий некоторую заданную функцию потерь, для достижения приемлемого уровня обобщающей способности}
	\scnrelfromvector{основные подходы}{
		обучение с учителем
		\scnaddlevel{1}
			\scnidtf{процесс изменения параметров и.н.с, минимизирующий разницу между выходом и.н.с. и целевой переменной для элементов обучающей выборки, относительно некоторой заданной функции потерь}
		\scnaddlevel{-1}
		;обучение без учителя
		\scnaddlevel{1}
			\scnidtf{процесс изменения параметров и.н.с. без использования заданных целевых переменных (в режиме самоорганизации)}
		\scnaddlevel{-1}
	}
\scnaddlevel{-1}

\scnheader{функция потерь}
\scnaddlevel{1}
	\scnidtf{функция, используемая для вычисления ошибки, рассчитываемой как разница между фактическим эталонным значением и прогнозируемым значением, получаемым и.н.с.}
	\scnrelfromvector{виды функций потерь}{
		MSE\\
		\scnaddlevel{1}
			\scnidtf{mean square error}
			\scnidtf{средняя квадратичная ошибка}
			\scnrelfrom{формула}{
				\begin{equation*}
					MSE = \frac{1}{m} \sum_{i=1}^m (y_i - e_i)^2
				\end{equation*}
				где $y_i$ -- прогноз модели, $e_i$ -- ожидаемый (эталонный) результат, \textit{m} -- размерность выходного вектора
			}
		\scnaddlevel{-1}
		;BCE\\
		\scnaddlevel{1}
			\scnidtf{binary cross entropy}
			\scnidtf{бинарная кросс-энтропия}
			\scnrelfrom{формула}{
				\begin{equation*}
					BCE = -(e \log(y) + (1 - e)\log(1 - y))
				\end{equation*}				
				где $y$ -- прогноз модели, $e$ -- ожидаемый (эталонный) результат: \textit{0} или \textit{1}
			}
			\scnnote{для бинарной кросс-энтропии в выходном слое и.н.с. будет находиться один нейрон}
		\scnaddlevel{-1}
		;MCE\\
		\scnaddhind{1}
			\scnidtf{multi-class cross entropy}
			\scnidtf{мультиклассовая кросс-энтропия}
			\scnrelfrom{формула}{
				\begin{equation*}
					MCE = - \sum_{i=1}^m e_{i} \log(y_{i})
				\end{equation*}
				где $y_{i}$ -- прогноз модели, $e_i$ -- ожидаемый (эталонный результат), \textit{m} -- размерность выходного вектора
			}
			\scnnote{для мультиклассовой кросс-энтропии количество нейронов в выходном слое и.н.с. совпадает с количеством классов}
		\scnaddlevel{-1}
	}
	\scnnote{для решения задачи классификации рекомендуется использовать бинарную или мультиклассовую кросс-энтропийную функцию потерь, для решения задачи регрессии рекомендуется использовать среднюю квадратичную ошибку}
\scnaddlevel{-1}

\scnheader{задачи, решаемые и.н.с.}
\scnaddlevel{1}
	\scnidtf{задачи, которые могут быть решены с помощью и.н.с. с приемлемой точностью}
	\scnrelfromvector{виды задач}{
		классификация экземпляров
			\scnaddlevel{1}
			\scnaddlevel{-1}
		;регрессия
			\scnaddlevel{1}
			\scnaddlevel{-1}
		;кластеризация
			\scnaddlevel{1}
			\scnaddlevel{-1}
		;предобработка данных
			\scnaddlevel{1}
			\scnaddlevel{-1}
		;понижение размерности
			\scnaddlevel{1}
			\scnaddlevel{-1}
	}
\scnaddlevel{-1}

%\scnheader{классификация экземпляров}
%
%\scnheader{регрессия}
%
%\scnheader{кластеризация}
%
%\scnheader{предобработка данных}
%
%\scnheader{понижение размерности}

\scnheader{целевая переменная}
\scnaddlevel{1}
	\scnidtf{цель}
	\scnidtf{target}
	\scnidtf{метка}
	\scnidtf{label}
	\scnidtf{численная или категориальная переменная, которая предсказывается для каждого нового экземпляра}
\scnaddlevel{-1}

\scnendstruct \scnendcurrentsectioncomment

\end{SCn}