.system_element_3814
=> nrel_inclusion: [*
	=> nrel_authors: 
		.system_element_3815;
		.system_element_3816;
		.system_element_3817;
		.system_element_3818;
		.system_element_3819
	;
	<- .system_element_3;
	-> rrel_key_sc_element: .system_element_3820;;

	.system_element_3820
	<- subject_domain;
	-> .system_element_6: 
		.system_element_3821;
		.system_element_3822;
		.system_element_3823;
		.system_element_3824;
		.system_element_3825;
		.system_element_3826
	;
	=> nrel_summary: [<p>Данная предметная область посвящена рассмотрению вопросов создания <i>аудио</i> и <i>речевых интерфейсов</i> для <i>интеллектуальных компьютерных систем нового поколения</i>. Предлагается использование подхода на основе онтологического проектирования и формализации системы понятий. Изложены основные идеи, лежащие в основе данного подхода, а также их отличительные особенности от общепринятых. Показано, что в перспективе использование данного подхода может обеспечить свойства <i>унификации</i>, <i>семантической совместимости</i> и <i>интероперабельности</i>, при разработке аудио и речевых интерфейсов, что в итоге позволит существенным образом сократить издержки при создании <i>интеллектуальных компьютерных систем нового поколения</i> для решении <i>комплексных задач</i>.</p>]
	(*
		<- lang_ru;;
		=> nrel_format: format_html;;
	*);
	=> .system_element_315: <
		.system_element_3827;
		.system_element_3828;
		.system_element_3829
	>;
	=> .system_element_11: 
		.system_element_3830;
		.system_element_3831;
		.system_element_3832;
		.system_element_3833;
		.system_element_3834;
		.system_element_3835;
		.system_element_3836;
		.system_element_3837;
		.system_element_3838;
		.system_element_3839;
		.system_element_3840;
		.system_element_3841;
		.system_element_3842;
		.system_element_3843;
		.system_element_835;
		.system_element_47;
		.system_element_416;
		.system_element_3844;
		.system_element_3845;
		.system_element_3846;
		.system_element_3847;
		.system_element_3848;
		.system_element_3849;
		.system_element_3850;
		.system_element_3851;
		.system_element_3852;
		.system_element_3853;
		.system_element_3854;
		.system_element_3855;
		.system_element_3856;
		.system_element_3857;
		.system_element_3858;
		.system_element_3859;
		.system_element_3860;
		.system_element_3861
	;
	=> nrel_introduction: <
		[<p>Разговорная речь является одной из наиболее естественных и эффективных форм передачи информации между людьми. Этот факт объясняет значительный интерес исследователей к вопросам развития и применения <i>речевых интерфейсов</i> для обеспечения человеко-машинного взаимодействия в составе современных коммуникационных, мультимедийных и интеллектуальных систем.</p>]
		(*
			<- lang_ru;;
			=> nrel_format: format_html;;
			=> .system_element_35: {
				.system_element_3831;
				.system_element_3830
			};;
		*);
		[<p>Более всеобъемлющей формой обеспечения взаимодействия с пользователем и окружающей средой посредством анализа и синтеза акустических сигналов является <i>аудиоинтерфейс</i>. Данную разновидность интерфейса, выступающей родительской по отношению к речевым, можно кратко определить как аппаратно-программный комплекс осуществляющий анализ и синтез сигналов во всем доступном спектре параметров носителей акустической информации. Например, для решения задач анализа обстановки и событий происходящих в акустическом окружении системы, синтеза неречевых сигналов (звуков техногенного и природного характера, сигналов оповещения, музыки, и так далее).</p>]
		(*
			<- lang_ru;;
			=> nrel_format: format_html;;
			=> .system_element_35: {
				.system_element_3832
			};;
		*);
		[<p>Об актуальности направления разработки аудио и речевых интерфейсов свидетельствуют следующие основные тенденции развития данного направления.</p>]
		(*
			<- lang_ru;;
			=> nrel_format: format_html;;
			=> .system_element_739: {
				[<p>Экономические показатели и прогнозы развития рынка речевых технологий, текущие среднегодовые темпы роста которого, по оценкам экспертов, составляют порядка 22%, а совокупный объем будет равен 59,6 млрд. долл. США к 2030.</p>]
				(*
					<- lang_ru;;
					=> nrel_format: format_html;;
					=> .system_element_35: {
						.system_element_3833
					};;
				*);
				[<p>Появление широкого спектра продуктов на основе речевого интерфейса, получивших массовое распространение. В первую очередь это персональные голосовые ассистенты, такие как "Alexa" (Amazon), "Siri" (Apple), "Сortana" (MicroSoft), "Алиса" (Yandex).</p>]
				(*
					<- lang_ru;;
					=> nrel_format: format_html;;
					=> .system_element_35: {
						.system_element_3834;
						.system_element_3835;
						.system_element_3836
					};;
				*);
				[<p>Интерес со стороны научного сообщества, выражающийся в росте публикаций в этом направлении исследований на 15% за последние 5 лет.</p>]
				(*
					<- lang_ru;;
					=> nrel_format: format_html;;
					=> .system_element_35: {
						.system_element_3837
					};;
				*)
			};;
		*);
		[<p>Необходимо отметить, что основная масса научных публикаций в данном направлении посвящена развитию базовых технологий, являющихся составляющими речевого интерфейса, таким как синтез речи по тексту, а также распознавание речи в текст. Последние достижения в этих направлениях связаны с бурным развитием нейросетевых моделей и вычислительных средств. Они позволили довести качественные характеристики использования речевых технологий до коммерческого уровня.</p>]
		(*
			<- lang_ru;;
			=> nrel_format: format_html;;
			=> .system_element_35: {
				.system_element_3842;
				.system_element_3838;
				.system_element_3840;
				.system_element_3839;
				.system_element_3841
			};;
		*);
		[<p>Большинство существующих систем, как правило, рассчитаны на решение определенного круга задач и сложно совместимы друг с другом. Данный факт в особенности остзличных <i>моделей решения задач</i>. Такие системы, кроме стандартных модулей распознавания (ASро проявляется при проектировании сложных систем, наподобие интеллектуальных персональных диалоговых ассистентов, требующих использования многообразия различных видов обрабатываемой информации и раR, automatic speech recognition) и синтеза (TTS, text to speech), на уровне аудиоинтерфейса также должны содержать модели, определяющие наличие/отсутствие речи в аудиосигнале в сложной акустической обстановке, классификации звуков окружающей среды, распознавание диктора и пр. Помимо этого элементы речевого интерфейса должны быть совместимы с более высокоуровневыми модулями обработки естественно-языковой информации, такими как модули понимания (SLU, spoken language understanding) и генерации речи (SLG, spoken language generation), управления диалогом (DM, dialog manager).</p>]
		(*
			<- lang_ru;;
			=> nrel_format: format_html;;
			=> .system_element_35: {
				.system_element_3843
			};;
			=> .system_element_203: "file://images/sd_ui/ch43_fig01_speech-hmi-components.png"
			(*
				<- concept_file;;
				=> nrel_format: format_png;;
				=> nrel_idtf: [<p>Рисунок. Компоненты системы человеко-машинного речевого диалога</p>]
				(*
					<- lang_ru;;
					=> nrel_format: format_html;;
				*);;
				=> .system_element_35: .system_element_3843;;
			*);;
		*);
		[<p>Все это требует разработки подходов, основанных не только на методах машинного обучения и обработке сигналов, но и на обработке естественного языка, символических методах искусственного интеллекта, онтологическом проектировании и формализации предметной области аудиоинтерфейса. Это позволит создать системы, которые обладают полным спектром знаний в формализованном виде о типах задач, которые они должны решать, и методах, доступных для их решения.</p>]
		(*
			<- lang_ru;;
			=> nrel_format: format_html;;
		*);
		[<p>Необходимым условием для создания таких систем нового поколения, обладающих улучшенными характеристиками по критериям <i>интероперабельности</i> и <i>гибкости</i> является также тот факт, что данные системы должны быть построены на основе базовой технологии, позволяющей обеспечить такое единство формы представления информации на всех ее уровнях.</p>]
		(*
			<- lang_ru;;
			=> nrel_format: format_html;;
		*);
		[<p>Совокупность данных факторов приводит к необходимости создания <i>интеллектуальных компьютерных систем нового поколения</i>, которые будут включать в себя модули аудио и речевого интерфейса, построенные на основе принципов интероперабельности и семантической совместимости для решения <i>комплексных задач</i>.</p>]
		(*
			<- lang_ru;;
			=> nrel_format: format_html;;
		*)
	>;;

	.system_element_3827
	=> nrel_inclusion: [*

		.system_element_3862
		=> .system_element_2130: <
			[<p>Для разработки аудиоинтерфейсов предлагается прибегнуть к подходу на основе принципов, лежащих в основе "Стандарта открытой технологии онтологического проектирования, производства и эксплуатации семантически совместимых гибридных интеллектуальных компьютерных систем" или кратко "Стандарта технологии OSTIS".</p>]
			(*
				<- lang_ru;;
				=> nrel_format: format_html;;
			*);
			[<p>Суть подхода заключается в рассмотрении процесса проектирования аудиоинтерфейса как интерфейсной подсистемы в рамках общего процесса разработки <i>интеллектуальной компьютерной системы</i> и построении ее формальной <i>логико-семантической модели</i>.</p>]
			(*
				<- lang_ru;;
				=> nrel_format: format_html;;
			*);
			[<p>Необходимо создать подобную модели интеллектуальной компьютерной системы нового поколения.</p>]
			(*
				<- lang_ru;;
				=> nrel_format: format_html;;
				=> .system_element_59: 
					[<p>Произведение декомпозиции информационной компьютерной системы на компоненты.</p>]
					(*
						<- lang_ru;;
						=> nrel_format: format_html;;
						=> nrel_note: [<p>Качество декомпозиции при этом определяется простотой последующего синтеза общей формальной модели из формальных моделей выделенных компонентов.</p>]
						(*
							<- lang_ru;;
							=> nrel_format: format_html;;
						*);;
					*);
					[<p>Произведение <i>конвергенции</i> выделенных компонентов в целях построения совместимых (легко интегрируемых) формальных моделей этих компонентов.</p>]
					(*
						<- lang_ru;;
						=> nrel_format: format_html;;
					*);
					[<p>Интеграция построенных формальных моделей выделенных компонентов и получение общей <i>формальной модели</i>.</p>]
					(*
						<- lang_ru;;
						=> nrel_format: format_html;;
					*);
					[<p>В качестве технологической основы для реализации предлагаемого подхода будет использоваться Технология OSTIS, соответственно подсистема аудиоинтерфейса будет строиться как <i>многократно используемый компонент</i>, который в будущем будет при необходимости встраиваться в различные ostis-системы.</p>]
					(*
						<- lang_ru;;
						=> nrel_format: format_html;;
					*)
				;;
			*)
		>;;

		technology_OSTIS
		=> .system_element_158: 
			[<p>В рамках указанной технологии предложены унифицированные средства представления различных видов знаний, в том числе --- <i>метазнаний</i>, что позволяет описать всю необходимую для анализа информацию в одной базе знаний в едином ключе.</p>]
			(*
				<- lang_ru;;
				=> nrel_format: format_html;;
				=> .system_element_35: {
					.system_element_47
				};;
			*);
			[<p>Используемый в рамках технологии формализм позволяет специфицировать в базе знаний не только понятия, но и любые внешние с точки зрения базы знаний файлы (например, фрагменты речевого сигнала), в том числе --- синтаксическую структуру таких файлов.</p>]
			(*
				<- lang_ru;;
				=> nrel_format: format_html;;
			*);
			[<p>Предложенный в рамках технологии подход к представлению различных видов знаний и моделей их обработки обеспечивает модифицируемость ostis-систем, то есть позволяет легко расширять функциональные возможности системы, вводя новые виды знаний (новые системы понятий) и новые модели обработки знаний.</p>]
			(*
				<- lang_ru;;
				=> nrel_format: format_html;;
				=> .system_element_35: {
					.system_element_47;
					.system_element_416
				};;
			*)
		;
		=> nrel_note: [<p>Более подробно принципы построения комплексной технологии разработки и поддержки жизненного цикла <i>интеллектуальных компьютерных систем нового поколения</i> --- <i>Технологии OSTIS</i> --- изложены в <i>Интеллектуальных компьютерных системах нового поколения</i>.</p>]
		(*
			<- lang_ru;;
			=> nrel_format: format_html;;
		*);
		=> .system_element_35: .system_element_3585;
		=> .system_element_3670: [<p>В отличие от различных работ авторов, посвященных вопросам семантического анализа голосовых сообщений на основе формализованного контекста и создания диалоговых ассистентов на основе модели ментального лексикона или мультимодальной системы на основе нейросимволического подхода, Технология OSTIS используется для непосредственного построения онтологии подсистем аудио интерфейса.</p>]
		(*
			<- lang_ru;;
			=> nrel_format: format_html;;
			=> .system_element_35: {
				.system_element_3845;
				.system_element_3846;
				.system_element_3847;
				.system_element_3844
			};;
		*);;

		.system_element_3863
		=> .system_element_173: [<p>аудиоинтерфейс <i>интеллектуальных компьютерных систем</i></p>]
		(*
			<- lang_ru;;
			=> nrel_format: format_html;;
		*);
		=> .system_element_189: {
			.system_element_3864;
			.system_element_3865;
			.system_element_3866
		};
		=> nrel_note: [<p><i>аудиоинтерфейс</i> <i>интеллектуальных компьютерных систем нового поколения</i> должен иметь архитектуру, соответствующую общим правилам построения ostis-систем.</p>]
		(*
			<- lang_ru;;
			=> nrel_format: format_html;;
		*);
		=> nrel_note: [<p>Согласно общим принципам организации интерфейсов ostis-систем, изложенным в <i>Общих принципах организации интерфейсов ostis-систем</i>, <i>аудио- и речевой интерфейс</i> относятся к подмножеству <i>SILK-интерфейсов</i> <i>пользовательских интерфейсов</i> <i>интеллектуальных компьютерных систем</i>.</p>]
		(*
			<- lang_ru;;
			=> nrel_format: format_html;;
		*);;

		.system_element_482
		=> .system_element_3867: [<p>Для решения задачи построения пользовательского интерфейса в базе знаний пользовательского интерфейса ostis-системы необходимо наличие <i>sc-модели</i> компонентов <i>пользовательского интерфейса</i>, интерфейсных действий пользователей, а также классификации пользовательских интерфейсов в целом. При проектировании интерфейса используется компонентный подход, который предполагает представление всего интерфейса приложения в виде отдельных <i>специфицированных компонентов</i>, которые могут разрабатываться и совершенствоваться независимо.Процесс разработки аудиоинтерфейса для <i>интеллектуальных компьютерных систем нового поколения</i>, подразумевает прежде всего создание семантически структурированных баз знаний в виде иерархической системы предметных областей и соответствующих им онтологий, специфицирующих эти предметные области. Следовательно, первым шагом для достижения поставленной цели должен являться этап выделения и формализации сущностей аудио и речевого интерфейса для погружения данной информации в базу знаний интеллектуальной компьютерной системы.</p>]
		(*
			<- lang_ru;;
			=> nrel_format: format_html;;
		*);;

		.system_element_3868
		=> nrel_decomposition: {
			.system_element_3869;
			.system_element_3829
		}
		(*
			=> nrel_note: [<p>В онтологию положен функциональный подход к декомпозиции предметных областей, что является вполне естественным, поскольку соответствует природе задач, реализуемых аудиоинтерфейсом.</p>]
			(*
				<- lang_ru;;
				=> nrel_format: format_html;;
			*);;
		*);;
	*];
	=> .system_element_3870: [<p>Представленные принципы в совокупности позволяют осуществлять конвергенцию и интеграцию компонентов как на уровне подсистемы аудиоинтерфейса, так и на уровне всей <i>интеллектуальной компьютерной системы нового поколения</i> в целом, что, в свою очередь, позволяет перевести <i>интеллектуальную информационную систему</i> в класс гибридных, <i>интероперабельных</i> и <i>семантически совместимых систем</i>.</p>]
	(*
		<- lang_ru;;
		=> nrel_format: format_html;;
	*);;

	.system_element_3828
	=> nrel_inclusion: [*
		=> nrel_note: [<p>Первым шагом на пути к построению базы знаний подсистемы аудиоинтерфейса <i>интеллектуальных компьютерных систем нового поколения</i> является формализация онтологии верхнего уровня. В основе данной онтологии предлагается положить формализованное представление основных сущностей предметной области и их свойств, а также функциональных задач, которые аудио и речевой интерфейс призваны решать.</p>]
		(*
			<- lang_ru;;
			=> nrel_format: format_html;;
		*);
		-> .system_element_6: 
			.system_element_3821;
			.system_element_3822;
			.system_element_3823;
			.system_element_3871
		
		(*
			=> nrel_note: [<p>Одним из ключевых понятий, требующих формализации, является базовое определение самого сигнала, а также основных разновидностей сигналов, в зависимости от их природы представляющих наибольший интерес в области аудиоинтерфейсов.</p>]
			(*
				<- lang_ru;;
				=> nrel_format: format_html;;
			*);;
		*);
		-> .system_element_6: 
			.system_element_3872;
			.system_element_3873;
			.system_element_3874;
			.system_element_3875;
			.system_element_3876;
			.system_element_3877;
			.system_element_3878;
			.system_element_3879;
			.system_element_3880
		
		(*
			=> nrel_note: [<p>Классы выделены в зависимости от способа математического описания обрабатываемого сигнала в ostis-системе.</p>]
			(*
				<- lang_ru;;
				=> nrel_format: format_html;;
			*);;
		*);
		-> .system_element_6: 
			.system_element_3881;
			.system_element_3882;
			.system_element_3883;
			.system_element_3884;
			.system_element_3885;
			.system_element_3886;
			.system_element_3887;
			.system_element_3888;
			.system_element_3889;
			.system_element_3890
		
		(*
			=> nrel_note: [<p>Понятия, связанные с характеристиками самого сигнала, по основным его атрибутам.</p>]
			(*
				<- lang_ru;;
				=> nrel_format: format_html;;
				=> .system_element_203: "file://images/sd_ui/ch43_fig02_speech-structure-segment-suprasegment.png"
				(*
					<- concept_file;;
					=> nrel_format: format_png;;
					=> nrel_idtf: [<p>Рисунок. Сегментные и надсегментные характеристики речевого сигнала</p>]
					(*
						<- lang_ru;;
						=> nrel_format: format_html;;
					*);;
				*);;
			*);;
		*);
		-> .system_element_6: 
			.system_element_3891;
			.system_element_3892;
			.system_element_3893;
			.system_element_3894;
			.system_element_3895;
			.system_element_3896
			(*
				=> nrel_idtf: [<p>Enviromental Sound Classification, Acoustic Scenes and Events</p>]
				(*
					<- lang_ru;;
					=> nrel_format: format_html;;
				*);;
			*);
			.system_element_3897
			(*
				=> nrel_idtf: [<p>Anomalous Sound Detection</p>]
				(*
					<- lang_ru;;
					=> nrel_format: format_html;;
				*);;
			*);
			.system_element_3898
			(*
				=> nrel_idtf: [<p>Sound Source Localization</p>]
				(*
					<- lang_ru;;
					=> nrel_format: format_html;;
				*);;
			*)
		;
		=> nrel_note: [<p>Понятия предметной области, лежащие в семантической окрестности подпространства функционального назначения аудиоинтерфейсов и обработки аудиосигналов.</p>]
		(*
			<- lang_ru;;
			=> nrel_format: format_html;;
		*);
		-> .system_element_6: 
			.system_element_3899;
			.system_element_3900;
			.system_element_3901;
			.system_element_3902;
			.system_element_3903
			(*
				=> nrel_idtf: [<p>Segmantal Features</p>]
				(*
					<- lang_ru;;
					=> nrel_format: format_html;;
				*);;
			*);
			.system_element_3904
			(*
				=> nrel_idtf: [<p>Suprasegmental Features</p>]
				(*
					<- lang_ru;;
					=> nrel_format: format_html;;
				*);;
			*);
			.system_element_3905;
			.system_element_3906;
			.system_element_3907;
			.system_element_3908;
			.system_element_3909
		
		(*
			=> nrel_note: [<p>Основные понятия аудио и речевого интерфейса также тесно связаны с основными его характеристиками, которые можно разделить на основные группы понятий.</p>]
			(*
				<- lang_ru;;
				=> nrel_format: format_html;;
			*);;
			=> .system_element_35: .system_element_3910;;
			=> .system_element_203: .system_element_3911;;
		*);
		-> .system_element_6: 
			.system_element_3912;
			.system_element_3913
			(*
				=> nrel_idtf: [<p>Key Words Spotting</p>]
				(*
					<- lang_ru;;
					=> nrel_format: format_html;;
				*);;
			*);
			.system_element_3914
			(*
				=> nrel_idtf: [<p>Wake Up Word Detection</p>]
				(*
					<- lang_ru;;
					=> nrel_format: format_html;;
				*);;
			*);
			.system_element_3915
			(*
				=> nrel_idtf: [<p>Voice Activity Detection</p>]
				(*
					<- lang_ru;;
					=> nrel_format: format_html;;
				*);;
			*);
			.system_element_3916;
			.system_element_3917
			(*
				=> nrel_idtf: [<p>Text-to-Speech Synthesis</p>]
				(*
					<- lang_ru;;
					=> nrel_format: format_html;;
				*);;
			*);
			.system_element_3918
			(*
				=> nrel_idtf: [<p>Emotional Text-to-Speech Syntehsis</p>]
				(*
					<- lang_ru;;
					=> nrel_format: format_html;;
				*);;
			*);
			.system_element_3919
			(*
				=> nrel_idtf: [<p>Sing Synthesis</p>]
				(*
					<- lang_ru;;
					=> nrel_format: format_html;;
				*);;
			*);
			.system_element_3920
			(*
				=> nrel_idtf: [<p>Emotional Speech Recognition</p>]
				(*
					<- lang_ru;;
					=> nrel_format: format_html;;
				*);;
			*);
			.system_element_3921;
			.system_element_3922
			(*
				=> nrel_idtf: [<p>speech diarization</p>]
				(*
					<- lang_ru;;
					=> nrel_format: format_html;;
				*);;
				=> nrel_idtf: [<p>speech separation</p>]
				(*
					<- lang_ru;;
					=> nrel_format: format_html;;
				*);;
			*);
			.system_element_3923
			(*
				=> nrel_idtf: [<p>Speaker Recognition</p>]
				(*
					<- lang_ru;;
					=> nrel_format: format_html;;
				*);;
			*);
			.system_element_3924
			(*
				=> nrel_idtf: [<p>Speaker Verification</p>]
				(*
					<- lang_ru;;
					=> nrel_format: format_html;;
				*);;
			*)
		;
		=> nrel_note: [<p>Основные понятия предметной области, лежащие в семантической окрестности функционального назначения речевого сигнала и обработки аудиосигналов.</p>]
		(*
			<- lang_ru;;
			=> nrel_format: format_html;;
		*);
		=> nrel_note: [<p>Необходимо отметить, что вышеобозначенные понятия зачастую сложным и нетривиальным образом связаны между собой в процессе перехода от источников информации к непосредственным физическим параметрам. Такую сложную структуру сигнала можно представить в виде схемы его информационной структуры. Этот факт требует от <i>интеллектуальных компьютерных систем нового поколения</i> формализации понятий для того, чтобы система могла автоматически интерпретировать взаимосвязи между данными характеристиками при работе с аудио и речевыми сигналами. И, как следствие, выдать ответ пользователю, объясняющий на основе каких характеристик система пришла к тому или иному выводу.</p>]
		(*
			<- lang_ru;;
			=> nrel_format: format_html;;
			=> .system_element_35: "file://images/sd_ui/ch43_fig03_speech-signal-inf-structure-ru.png"
			(*
				<- concept_file;;
				=> nrel_format: format_png;;
				=> nrel_idtf: [<p>Рисунок. Информационная структура речевого сигнала</p>]
				(*
					<- lang_ru;;
					=> nrel_format: format_html;;
				*);;
			*);;
			=> .system_element_35: .system_element_3925;;
		*);;

		.system_element_3926
		=> nrel_note: [<p>Для построения <i>интеллектуальных компьютерных систем нового поколения</i> в фокусе лежат задачи, связанные с обработкой речевых сигналов, решение которых необходимо в первую очередь для построения речевого интерфейса.</p>]
		(*
			<- lang_ru;;
			=> nrel_format: format_html;;
		*);
		=> nrel_note: [<p>Основу <i>sc-модели базы знаний</i> составляет иерархическая система предметных областей и соответствующих им онтологий.</p>]
		(*
			<- lang_ru;;
			=> nrel_format: format_html;;
		*);
		=> nrel_note: [<p>В зависимости от модели представления сигнала в ostis-системе также могут быть определены различные описания основных видов сигналов, применение которых обосновано особенностями природы анализируемого сигнала, а также решаемой задачей анализа.</p>]
		(*
			<- lang_ru;;
			=> nrel_format: format_html;;
			=> .system_element_35: .system_element_3927;;
		*);
		=> nrel_note: [<p>Важным аспектом в процессе проектирования является формализация <i>классов задач</i> аудиоинтерфейса, поскольку благодаря этим знаниям в интеллектуальной системе могут (и должны) применяться соответствующие методы обработки, в зависимости от типа решаемой задачи.</p>]
		(*
			<- lang_ru;;
			=> nrel_format: format_html;;
			=> .system_element_35: "file://images/sd_ui/ch43_fig04_audio-and-speech-tasks-formalization-ru.png"
			(*
				<- concept_file;;
				=> nrel_format: format_png;;
				=> nrel_idtf: [<p>SCg-текст. Фрагмент онтологии верхнего уровня задач аудио- и речевых интерфейсов для интеллектуальных компьютерных систем нового поколения</p>]
				(*
					<- lang_ru;;
					=> nrel_format: format_html;;
				*);;
				=> nrel_note: [<p>Фрагмент онтологии верхнего уровня типовых <i>задач</i> решаемых <i>интеллектуальной компьютерной системой</i> в области обработки аудио- и речевых сигналов.</p>]
				(*
					<- lang_ru;;
					=> nrel_format: format_html;;
				*);;
			*);;
		*);;

		.system_element_3821
		=> .system_element_264: [<p>сигнал --- это физический процесс, несущий сообщение (информацию) о каком-либо событии, состоянии объекта наблюдения либо передающий команды управления, оповещения и так далее.</p>]
		(*
			<- lang_ru;;
			=> nrel_format: format_html;;
		*);
		=> nrel_inclusion: .system_element_3871
		(*
			=> .system_element_264: [<p>акустический сигнал --- это сигнал, представляющий собой распространение упругих волн в газообразной, жидкой или твердой среде.</p>]
			(*
				<- lang_ru;;
				=> nrel_format: format_html;;
			*);;
		*);
		=> nrel_inclusion: .system_element_3822
		(*
			=> nrel_idtf: [<p>слышимый звуковой сигнал</p>]
			(*
				<- lang_ru;;
				=> nrel_format: format_html;;
			*);;
			=> .system_element_264: [<p>аудиосигнал --- это акустический сигнал, параметры которого находятся в пределах диапазона значений доступного для восприятия органами чувств человека.</p>]
			(*
				<- lang_ru;;
				=> nrel_format: format_html;;
			*);;
			=> nrel_inclusion: .system_element_3871;;
			=> nrel_note: [<p>Диапазон частот аудиосигнала лежит в интервале от 20 до 20 000 Гц.</p>]
			(*
				<- lang_ru;;
				=> nrel_format: format_html;;
			*);;
		*);
		=> nrel_inclusion: .system_element_3823
		(*
			=> .system_element_264: [<p>речевой сигнал --- это аудиосигнал, который образуется в результате прохождения воздушных потоков через речевой тракт человека. В результате всевозможных акустических преобразований происходит формирование различных звуков речи.</p>]
			(*
				<- lang_ru;;
				=> nrel_format: format_html;;
			*);;
			-> .system_element_3928;;
			-> .system_element_3929;;
			=> nrel_note: [<p>Механизм речеобразования человека представляет собой акустическую трубу с динамически изменяющимися параметрами поперечного сечения, возбуждаемую либо квазипериодической последовательностью импульсов, генерируемых голосовыми связками, либо турбулентным потоком воздуха, проталкиваемого сквозь сужения, в разных местах речевого тракта.</p>]
			(*
				<- lang_ru;;
				=> nrel_format: format_html;;
			*);;
		*);;

		.system_element_3927
		<= nrel_combination: {
			.system_element_3872
			(*
				=> .system_element_264: [<p>аналоговый сигнал --- сигнал параметры которого можно измерить в любой момент времени.</p>]
				(*
					<- lang_ru;;
					=> nrel_format: format_html;;
				*);;
				=> .system_element_264: [<p>аналоговый сигнал --- сигнал, у которого каждый из представленных параметров описывается функцией времени и непрерывным множеством возможных значений.</p>]
				(*
					<- lang_ru;;
					=> nrel_format: format_html;;
				*);;
			*);
			.system_element_3873
			(*
				=> .system_element_264: [<p>дискретный сигнал --- сигнал, у которого хотя бы один из представленных параметров описывается конечным множеством возможных значений.</p>]
				(*
					<- lang_ru;;
					=> nrel_format: format_html;;
				*);;
				<= nrel_combination: {
					.system_element_3930;
					.system_element_3931
				};;
			*);
			.system_element_3874
			(*
				=> .system_element_264: [<p>цифровой сигнал --- сигнал, у которого каждый из представляющих параметров описывается функцией дискретного времени и конечным множеством возможных значений.</p>]
				(*
					<- lang_ru;;
					=> nrel_format: format_html;;
				*);;
				=> .system_element_3932: {
					.system_element_3933;
					.system_element_3934
				};;
			*);
			.system_element_3875;
			.system_element_3876;
			.system_element_3878;
			.system_element_3877;
			.system_element_3935;
			.system_element_3879
		};;

		.system_element_3936
		<= nrel_combination: {
			.system_element_3881;
			.system_element_3882;
			.system_element_3883;
			.system_element_3884;
			.system_element_3885;
			.system_element_3937;
			.system_element_3888;
			.system_element_3887
			(*
				=> .system_element_264: [<p>осцилограмма сигнала --- функция фиксирующая зависимость изменения характеристик сигнала (в первую очередь амплитуды) от времени.</p>]
				(*
					<- lang_ru;;
					=> nrel_format: format_html;;
				*);;
			*);
			.system_element_3938
			(*
				=> .system_element_264: [<p>спектрограмма сигнала --- функция, фиксирующая зависимость спектральной плотности мощности аудиосигнала от времени.</p>]
				(*
					<- lang_ru;;
					=> nrel_format: format_html;;
				*);;
			*);
			.system_element_3889
			(*
				=> .system_element_264: [<p>частота дискретизации сигнала --- значение частоты, с которой производилась дискретизация сигнала по времени в процессе аналогово-цифрового преобразования.</p>]
				(*
					<- lang_ru;;
					=> nrel_format: format_html;;
				*);;
				<= .system_element_3939: {
					.system_element_3940;
					.system_element_3941;
					.system_element_3942;
					.system_element_3943;
					.system_element_3944
				};;
			*);
			.system_element_3945
			(*
				=> .system_element_264: [<p>уровень квантования сигнала --- допустимое количество дискретных уровней сигнала выраженное как степень двойки и применяемое в процессе квантования сигнала по уровню в процессе аналогово-цифрового преобразования.</p>]
				(*
					<- lang_ru;;
					=> nrel_format: format_html;;
				*);;
				<= .system_element_3939: {
					.system_element_3946;
					.system_element_3947;
					.system_element_3948;
					.system_element_3949;
					.system_element_3950
				};;
			*)
		}
		(*
			=> nrel_note: [<p>Необходимо отметить, что по причине ограничений на размер материала для характеристик аудиосигнала приведена только иерархию общей их взаимосвязи, поскольку семантика данных понятий вполне характерна и для других областей технических наук и не требует подробных примеров и пояснений.</p>]
			(*
				<- lang_ru;;
				=> nrel_format: format_html;;
			*);;
		*);;

		.system_element_3951
		<= nrel_combination: {
			.system_element_3952
			(*
				=> nrel_note: [<p>Кодирует смысл передаваемого сообщения, зависит от намерений отправителя.</p>]
				(*
					<- lang_ru;;
					=> nrel_format: format_html;;
				*);;
			*);
			.system_element_3953
			(*
				=> nrel_note: [<p>Кодирует дополнительную информацию передаваемого сообщения, не зависит от намерений отправителя.</p>]
				(*
					<- lang_ru;;
					=> nrel_format: format_html;;
				*);;
			*);
			.system_element_3953
			(*
				=> nrel_note: [<p>Кодирует дополнительную информацию передаваемого сообщения, не зависит от намерений отправителя.</p>]
				(*
					<- lang_ru;;
					=> nrel_format: format_html;;
				*);;
			*);
			.system_element_3903
			(*
				=> nrel_note: [<p>Несет информацию о текущем состоянии источника на протяжении длительности одной или нескольких фонетичесих единиц.</p>]
				(*
					<- lang_ru;;
					=> nrel_format: format_html;;
				*);;
			*);
			.system_element_3904
			(*
				=> nrel_note: [<p>Несет информацию о состоянии источника и переходах между ними на протяжении времени всего высказывания.</p>]
				(*
					<- lang_ru;;
					=> nrel_format: format_html;;
				*);;
			*)
		};
		=> nrel_inclusion: .system_element_3954
		(*
			-> .system_element_3955;;
			-> .system_element_3952;;
			=> .system_element_264: [<p>лингвистическая характеристика сигнала --- характеристика несущая информацию по средствам использованием системы кодирования человеческого языка.</p>]
			(*
				<- lang_ru;;
				=> nrel_format: format_html;;
			*);;
			=> nrel_note: [<p>лингвистическая характеристика включает как фонологический код (сегментарный и надсегментный), так и грамматический код (морфологию и синтаксис). Лингвистическая коммуникация информирует получателя о намерениях отправителя с помощью явных словесных форм.</p>]
			(*
				<- lang_ru;;
				=> nrel_format: format_html;;
			*);;
		*);
		=> nrel_inclusion: .system_element_3956
		(*
			-> .system_element_3957;;
			-> .system_element_3952;;
			=> .system_element_264: [<p>паралингвистическая характеристика сигнала --- характеристика несущая информацию посредством  дополнительных средств коммуникации не связанных непосредственно с языком.</p>]
			(*
				<- lang_ru;;
				=> nrel_format: format_html;;
			*);;
			=> nrel_note: [<p>Передает информацию об отношении к предмету разговора, чувствах или эмоциональном состоянии говорящего.</p>]
			(*
				<- lang_ru;;
				=> nrel_format: format_html;;
			*);;
			<= nrel_combination: {
				.system_element_3958
				(*
					<= nrel_combination: {
						.system_element_3959;
						.system_element_3960
					};;
				*);
				.system_element_3961
				(*
					<= nrel_combination: {
						.system_element_3962;
						.system_element_3884
					};;
				*);
				.system_element_3963;
				.system_element_3964
			};;
		*);
		=> nrel_inclusion: .system_element_3965
		(*
			-> .system_element_3953;;
			=> .system_element_264: [<p>экстралингвистическая характеристика сигнала --- характеристика, которые не кодируют непосредственно смысл сообщения, но содержит дополнительную информацию об отправителе и условиях коммуникации.</p>]
			(*
				<- lang_ru;;
				=> nrel_format: format_html;;
			*);;
			=> nrel_note: [<p>Передает информацию об отношении к предмету разговора, чувствах или эмоциональном состоянии говорящего.</p>]
			(*
				<- lang_ru;;
				=> nrel_format: format_html;;
			*);;
			<= nrel_combination: {
				.system_element_3966
				(*
					<= nrel_combination: {
						.system_element_3967;
						.system_element_3968;
						.system_element_3969
					};;
				*);
				.system_element_3970
			};;
		*);;
	*];
	=> nrel_conclusion: [<p>Представлен результат формализации средствами <i>SCg-кода</i> предметной области и онтологии типовых задач аудио и речевых интерфейсов для <i>интеллектуальных компьютерных систем нового поколения</i>.Необходимо отметить, что были представлены варианты формализации ключевых понятий области, на основе имеющихся источников информации. Более полные результаты работы по формализации предметной области <i>аудиоинтерфейса</i> требуют доступа к закрытым стандартам <i>AES</i>, <i>ISO</i> и <i>IEEE</i>, а также привлечения более широкого круга экспертов, результаты работы с которыми будут фиксироваться в следующих вариантах стандарта.</p>]
	(*
		<- lang_ru;;
		=> nrel_format: format_html;;
	*);;

	.system_element_3829
	=> nrel_inclusion: [*
		=> nrel_note: [<p>Все задачи аудио и речевых интерфейсов взаимосвязаны, поскольку относятся к одному и тому же объекту исследования --- <i>речевому сигналу</i>. Решение каждой из них непосредственно либо косвенно зависит от эффективности моделирования речи как сложного феномена в различных аспектах: параметрическое представление речевого сигнала и выделение его свойств, моделирование процесса фонации, восприятия и интерпретации содержания речевого сообщения (в том числе фонетического, смыслового, эмоционального). Это делает создание универсальных способов обработки речевых сигналов перспективным научным направлением.</p>]
		(*
			<- lang_ru;;
			=> nrel_format: format_html;;
		*);;

		.system_element_3971
		=> nrel_note: [<p>В контексте задач аудио и речевых интерфейсов моделирование речи можно условно разделить на три уровня.</p>]
		(*
			<- lang_ru;;
			=> nrel_format: format_html;;
		*);
		=> .system_element_3972: <
			[<p>Моделирование сигнала в общем виде, используя отсчеты во временной или частотной области.</p>]
			(*
				<- lang_ru;;
				=> nrel_format: format_html;;
			*);
			[<p>Моделирование характеристик сигнала, являющихся специфическими для речи и связанных с процессом фонации.</p>]
			(*
				<- lang_ru;;
				=> nrel_format: format_html;;
				=> .system_element_203: 
					.system_element_3973;
					.system_element_3974;
					.system_element_3975
				;;
			*);
			[<p>Моделирование высокоуровневых речевых характеристик.  Каждый следующий уровень основывается на предыдущем и подразумевает использование специальных методов параметрического описания.</p>]
			(*
				<- lang_ru;;
				=> nrel_format: format_html;;
				=> .system_element_203: 
					.system_element_3976;
					.system_element_3977;
					.system_element_3978;
					.system_element_3979;
					.system_element_3980
				;;
			*)
		>
		(*
			=> nrel_note: [<p>К первым двум уровням относятся широко известные в цифровой обработке речевых сигналов модели на основе линейного предсказания, кепстральных коэффициентов и синусоидальных параметров. Отличительные особенности основных типов моделей представлены на рисунке "Отличительные особенности  основных типов моделей параметрического представления сигнала."</p>]
			(*
				<- lang_ru;;
				=> nrel_format: format_html;;
				=> .system_element_203: "file://images/sd_ui/ch43_fig05_signal-model-types-ru.png"
				(*
					<- concept_file;;
					=> nrel_format: format_png;;
					=> nrel_idtf: [<p>Рисунок. Отличительные особенности  основных типов моделей параметрического представления сигнала</p>]
					(*
						<- lang_ru;;
						=> nrel_format: format_html;;
					*);;
				*);;
			*);;
		*);;

		.system_element_3981
		=> nrel_note: [<p>Среди подходов, использующих синусоидальное описание сигнала, в настоящее время наиболее перспективными являются смешанные (гибридные) модели, учитывающие возможность разных режимов фонации с участием голосовых связок (вокализованная речь) и без участия голосовых связок (невокализованная речь), причем каждый из этих двух режимов описывается соответствующей моделью.</p>]
		(*
			<- lang_ru;;
			=> nrel_format: format_html;;
		*);;

		.system_element_3982
		=> .system_element_264: [<p>вокализованная речь --- это речь с участием голосовых связок.</p>]
		(*
			<- lang_ru;;
			=> nrel_format: format_html;;
		*);
		=> nrel_note: [<p>вокализованная речь рассматривается как квазипериодический (детерминистский) сигнал.</p>]
		(*
			<- lang_ru;;
			=> nrel_format: format_html;;
		*);
		=> nrel_note: [<p>Поскольку вокализованная речь состоит из квазипериодических компонент с изменяющимися параметрами, для анализа необходимо использовать цифровые фильтры с изменяющимися характеристиками: их полоса пропускания должна меняться в соответствии с контуром частоты основного тона. Это требует использования специальных частотно-временных преобразований, позволяющих производить оценку периодических составляющих с сильной частотной модуляцией, таких как Фан-Чирп и гармоническое преобразования. Точность оценки параметров непосредственно связана с точностью оценки контура основного тона, поэтому использование надежного и точного способа оценки является необходимым условием для успешного использования данной модели.</p>]
		(*
			<- lang_ru;;
			=> nrel_format: format_html;;
			=> .system_element_35: {
				.system_element_3852;
				.system_element_3853;
				.system_element_3854
			};;
		*);;

		.system_element_3983
		=> .system_element_264: [<p>невокализованная речь --- это речь без участия голосовых связок.</p>]
		(*
			<- lang_ru;;
			=> nrel_format: format_html;;
		*);
		=> nrel_note: [<p>невокализованная речь представляет собой непериодический (стохастический) сигнал.</p>]
		(*
			<- lang_ru;;
			=> nrel_format: format_html;;
		*);;

		.system_element_3984
		=> .system_element_488: 
			.system_element_3985;
			.system_element_3606;
			.system_element_3986;
			.system_element_3987;
			.system_element_3988;
			.system_element_3989;
			.system_element_3990
		;
		=> .system_element_158: [<p>Теоретическая возможность моделирования вокализованных звуков в виде непрерывных функций с изменяющимися параметрами, что позволяет получить эффективное описание процесса фонации и избежать наложения смежных фрагментов, разрыва фаз при синтезе речи.</p>]
		(*
			<- lang_ru;;
			=> nrel_format: format_html;;
		*);
		=> .system_element_237: [<p>Высокая сложность алгоритмов анализа и синтеза, обусловленная нестационарностью речевого сигнала.</p>]
		(*
			<- lang_ru;;
			=> nrel_format: format_html;;
			=> .system_element_35: {
				.system_element_3851;
				.system_element_3848;
				.system_element_3849;
				.system_element_3850
			};;
		*);;

		.system_element_3991
		=> .system_element_488: [<p>Автоматическое разделение сигнала на детерминистскую и стохастическую составляющие.</p>]
		(*
			<- lang_ru;;
			=> nrel_format: format_html;;
		*);;

		.system_element_3992
		=> nrel_note: [<p>Моделирование речевого сигнала на основе линейного предсказания является классическим подходом, который применяется в цифровой обработке речи достаточно продолжительное время.</p>]
		(*
			<- lang_ru;;
			=> nrel_format: format_html;;
		*);
		=> .system_element_158: 
			[<p>Раздельное описание сигнала в виде огибающей спектра и сигнала возбуждения. Огибающая спектра определяет фонетику произносимого звука и характеризует состояние речевого тракта, в то время как сигнал возбуждения характеризует состояние голосовых связок и высоту (интонацию) вокализованных звуков.</p>]
			(*
				<- lang_ru;;
				=> nrel_format: format_html;;
			*);
			[<p>Низкая вычислительная сложность.</p>]
			(*
				<- lang_ru;;
				=> nrel_format: format_html;;
			*)
		;;

		.system_element_3981
		=> nrel_note: [<p>В последнее время предпочтение отдается моделям, использующим синусоидальное представление сигнала и в первую очередь это касается приложений, подразумевающих синтез речевого сигнала с измененными параметрами, таких как изменение интонации, конверсия голоса, синтез речи по тексту и других. Данный факт можно объяснить тем, что линейное предсказание не обеспечивает эффективных способов для параметрической обработки сигнала возбуждения и непрерывного синтеза выходного сигнала. Каждый речевой фрагмент (кадр) сигнала представляет собой отдельную независимую единицу и при синтезе возникает проблема согласования соседних кадров. Несогласованное изменение огибающей амплитудного и фазового спектра при переходе от кадра к кадру вызывает появление слышимых артефактов. Кроме того, оценка огибающей спектра при помощи классических методов линейного предсказания представляет собой усреднение по всему кадру, вследствие чего ее точность ограничена. Порядок предсказателя определяет сложность модели: для предсказателей низких порядков оценка огибающей спектра получается чрезмерно сглаженной, а для предсказателей высоких порядков точность становится избирательной. Для точек спектра, соответствующих гармоникам основного тона, точность повышается, а для всех остальных точек --- снижается. Оптимальный порядок предсказателя зависит от высоты голоса, но даже в наиболее благоприятном случае точность оценки огибающей спектра имеет погрешность, приводящую к возникновению слышимых искажений.</p>]
		(*
			<- lang_ru;;
			=> nrel_format: format_html;;
		*);
		=> .system_element_2928: [<p>Благодаря своим широким возможностям гибридная модель на основе синусоидальных параметров является наиболее предпочтительной для использования в большинстве практических случаев. Тем не менее для преодоления существующих ее ограничений, связанных со сложностью оценки параметров, их интерпретации в виде специфических речевых характеристик (параметры речевого тракта, последовательность возбуждения) требуется разработка специальных методов моделирования.</p>]
		(*
			<- lang_ru;;
			=> nrel_format: format_html;;
		*);;

		.system_element_3993
		=> nrel_note: [<p>Использование кепстральных коэффициентов для моделирования речевых сигналов является классическим подходом. Наиболее хорошо разработанной системой моделирования речевых сигналов, использующей кепстральные коэффициенты, является <i>TANDEM-STRAIGHT</i>.</p>]
		(*
			<- lang_ru;;
			=> nrel_format: format_html;;
			=> .system_element_35: {
				.system_element_3855;
				.system_element_3856
			};;
		*);
		=> nrel_note: [<p>Так же как и для классических способов анализа на основе линейного предсказания, при оценке кепстральных коэффициентов предполагается стационарность сигнала на протяжении интервала наблюдения. Оценка огибающей амплитудного спектра требует сглаживания и также недостаточно точна по сравнению с моделями на основе синусоидальных.</p>]
		(*
			<- lang_ru;;
			=> nrel_format: format_html;;
			=> .system_element_203: "file://images/sd_ui/ch43_fig06_straight-spectrum.png"
			(*
				<- concept_file;;
				=> nrel_format: format_png;;
				=> nrel_idtf: [<p>Рисунок. Спектрограмма сигнала на основе ДПФ (слева) и спектрограмма TANDEM-STRAIGHT (справа)</p>]
				(*
					<- lang_ru;;
					=> nrel_format: format_html;;
				*);;
			*);;
		*);;

		.system_element_3994
		=> nrel_subdividing: <
			.system_element_462
			(*
				=> nrel_note: [<p>Определение параметров модели.</p>]
				(*
					<- lang_ru;;
					=> nrel_format: format_html;;
				*);;
			*);
			.system_element_3995
			(*
				=> nrel_note: [<p>Изменение параметров модели в зависимости от цели приложения.</p>]
				(*
					<- lang_ru;;
					=> nrel_format: format_html;;
				*);;
			*);
			.system_element_3996
			(*
				=> nrel_note: [<p>Формирование нового сигнала из измененных параметров модели.</p>]
				(*
					<- lang_ru;;
					=> nrel_format: format_html;;
				*);;
			*)
		>
		(*
			=> nrel_note: [<p>Для обеспечения наиболее высокой практической значимости разрабатываемые методы моделирования должны включать средства анализа, обработки параметров и синтеза.</p>]
			(*
				<- lang_ru;;
				=> nrel_format: format_html;;
			*);;
		*);
		=> nrel_note: [<p>Для решения многих современных прикладных задач требуется не только наличие возможности описания речевого сигнала или процесса фонации, но и использование высокоуровневых речевых характеристик, определяющих персональный голос диктора, экспрессию, фонетику и так далее. К таким задачам относятся конверсия голоса, синтез речи по тексту, верификация диктора и многие другие. Высокоуровневое моделирование речи является очень сложной предметной областью, поскольку требует использования интеллектуальных моделей и методов машинного обучения. На данный момент не существует единого универсального способа, применяемого для разных приложений.</p>]
		(*
			<- lang_ru;;
			=> nrel_format: format_html;;
		*);;

		.system_element_3997
		=> .system_element_264: [<p>параметрическая модель сигнала --- математическое выражение, используемое для представления отсчетов сигнала во временной или частотной области.</p>]
		(*
			<- lang_ru;;
			=> nrel_format: format_html;;
		*);
		=> nrel_inclusion: .system_element_3998
		(*
			=> .system_element_264: [<p>параметрическая модель речевого сигнала --- математическое описание характеристик сигнала, являющихся специфическими для речи и связанных с процессом фонации (таких как частота основного тона, последовательность возбуждения и огибающая амплитудного спектра).</p>]
			(*
				<- lang_ru;;
				=> nrel_format: format_html;;
			*);;
			=> nrel_note: [<p>К основным моделям речевого сигнала относят: модели на основе линейного предсказания; на основе кепстрального представления; синусоидальные и гибридные модели. Среди гибридных моделей наиболее известна модель гармоники+шум.</p>]
			(*
				<- lang_ru;;
				=> nrel_format: format_html;;
			*);;
		*);;

		.system_element_3999
		=> nrel_note: [<p>Подавляющее большинство высокоуровневых речевых моделей, используемых на практике, являются проблемно-ориентированными и могут применяться только для решения одной, узкоспециализированной задачи. Поэтому критически важным является факт того, чтобы в <i>базе знаний</i> <i>интеллектуальной компьютерной системы</i> содержалось достаточно информации для определения подходящего типа модели представления сигнала и активации соответствующего <i>агента</i> в рамках <i>многоагентной системы</i> в зависимости от класса м модели решаемой задачи.</p>]
		(*
			<- lang_ru;;
			=> nrel_format: format_html;;
			=> .system_element_35: .system_element_1709;;
		*);;
	*];
	=> nrel_conclusion: <
		[<p>Изложены идеи, лежащие в основе оригинального подхода к проектированию аудиоинтерфейсов <i>интеллектуальных компьютерных систем</i> на основе онтологического проектирования и формализации системы понятий из соответствующей предметной области, с использованием Технологии OSTIS. Изложены основные принципы лежащие в основе данного подхода, а также их отличительные особенности от общепринятых.</p>]
		(*
			<- lang_ru;;
			=> nrel_format: format_html;;
		*);
		[<p>К ограничениям предлагаемого подхода можно отнести следующие основные факторы.  Очевидно, что для достижения поставленной цели и реализации задач по формализации любой предметной области, в том числе и аудиоинтерфейсов, требуется в первую очередь большое количество источников знаний для их пополнения. 
		<li> Для преодоления данной проблемы требуется привлечение большого количества экспертов, обладающих соответствующими компетенциями и знаниями в предметной области, либо же разработка механизмов надежного автоматического извлечения этих знаний из имеющихся источников.</p>]
		(*
			<- lang_ru;;
			=> nrel_format: format_html;;
		*);
		[<p>Прямой доступ к знаниям экспертов весьма ограничен, поскольку это требует значимых усилий по подбору репрезентативной выборки таких экспертов, выстраиванию эффективных и интероперабельных взаимоотношений между сторонами процесса, что зачастую зависит от большого количества субъективных факторов, --- соответственно, требует большого количества временных и материальных ресурсов.</p>]
		(*
			<- lang_ru;;
			=> nrel_format: format_html;;
		*);
		[<p>Известно, что существенное количество информации, накопленной человечеством, хранится в виде текстов на естественных языках. Процесс извлечения данной информации и представления ее в формализованном виде --- в виде знаний, также выглядит нетривиальным.</p>]
		(*
			<- lang_ru;;
			=> nrel_format: format_html;;
		*);
		[<p>Исходя из природы данных проблем, по мнению авторов, видятся следующие основные направления их преодоления и, как следствие, две основные стратегии развития предложенного подхода.</p>]
		(*
			<- lang_ru;;
			=> nrel_format: format_html;;
			=> .system_element_739: 
				[<p>Создание для экспертов, работающих в домене аудио и речевых интерфейсов, специализированных инструментальных средств по формализации и представлению знаний из данной предметной области, фиксации их в виде стандартов единой формы. Подобные инструменты должны обладать качественно новыми функциональными возможностями, обеспечивающими высокий уровень совместимости и интероперабельности в процессе накопления и стандартизации знаний, чтобы сами эксперты были заинтересованы в применении и широком распространении данной технологии для представления знаний. Данный пункт является одной из ключевых задач <i>Технологии OSTIS</i> и <i>Стандарта OSTIS</i>.</p>]
				(*
					<- lang_ru;;
					=> nrel_format: format_html;;
				*);
				[<p>Создание автоматизированных и автоматических средств извлечения знаний из существующих источников информации, в первую очередь текстов на естественном языке. К видам документов, в которых содержится уже структурированная и отчасти формализованная информация, относятся в первую очередь: стандарты, протоколы, рекомендации (RFC), инструкции и так далее. Следовательно процесс автоматизации извлечения знаний должен быть направлен в первую очередь на формализацию уже существующих отраслевых стандартов разработки аудиоинтерфейсов, систем обработки и кодирования аудиоинформации, систем обработки речевых сигналов, таких как стандарты серии <i>ISO</i>, <i>IEEE</i> и <i>AES</i> (Audio Engineering Society): <i>ISO14496-3</i>, <i>ISO23003-3</i>, <i>IEEE1857-8</i>, <i>IEC62087-2</i>, <i>AES3250</i>.</p>]
				(*
					<- lang_ru;;
					=> nrel_format: format_html;;
					=> .system_element_35: {
						.system_element_3857;
						.system_element_3858;
						.system_element_3859;
						.system_element_3860;
						.system_element_3861
					};;
				*)
			;;
		*);
		[<p>Реализация подхода, предложенного в данной данной предметной области, позволит обеспечить свойства унификации, семантической совместимости и интероперабельности, при разработке аудио и речевых интерфейсов (своеобразный аналог <i>Модели OSI/ISO</i> в области проектирования <i>интерфейсов</i> <i>интеллектуальных компьютерных систем</i>), что в итоге позволит существенным образом сократить издержки при создании интеллектуальных компьютерных систем нового поколения для решении сложных комплексных задач.</p>]
		(*
			<- lang_ru;;
			=> nrel_format: format_html;;
		*)
	>;;
*];;
